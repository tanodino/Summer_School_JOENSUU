{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Discovery of satellite data through a STAC catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Author(s):** Quentin Yeche, Kenji Ose, Dino Ienco - [UMR TETIS](https://umr-tetis.fr) / [INRAE](https://www.inrae.fr/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### 1.1. Satellite data access: emergence of cloud native solutions\n",
    "\n",
    "There are several possibilities to **discover** and **download** satellite images. In a fairly classic way, we discover and download the images on websites. If we take the example of data from the Sentinel constellation, we connect to the [SchiHub website](https://scihub.copernicus.eu/) of the Copernicus program.\n",
    "\n",
    "However, there are other recent solutions based on new specifications. They make it possible to optimize in particular the download by targeting only the useful portions of the images.\n",
    "\n",
    "This first notebook introduces the [STAC](https://stacspec.org/en) (SpatioTemporal Asset Catalog) specification and outlines a practical and convenient method for searching and obtaining spatiotemporal assets.\n",
    "\n",
    "Here we will use Microsoft's Planetary Computer's STAC Python API, but STAC is meant to be a standard that other data providers can adhere to.\n",
    "\n",
    "### 1.2. STAC Specification\n",
    "\n",
    "The STAC specification actually encompasses 4 semi-independent specifications:\n",
    "  1. STAC Item\n",
    "  2. STAC Catalog\n",
    "  3. STAC Collection\n",
    "  4. (STAC API)\n",
    "\n",
    "***Note:** The STAC API provides specification for a RESTful endpoint (which is how the Python library `pystac` interacts with servers in the background) and falls outside the context of these notebooks.*\n",
    "\n",
    "The Item, Catalog and Collection specifications describe JSON objects with specific fields. Any JSON object that contains all the required fields for an Item (resp. Catalog, Collection) is a valid STAC Item (resp. Catalog, Collection). These JSON objects themselves do not contain any data, they store only metadata and links (more precisely URIs) to the data.\n",
    "\n",
    "STAC Items are the smallest unit of the STAC specification. An Item represents one or several spatiotemporal assets. A STAC Catalog object is simply a group of other Catalog, Collection, and Item objects. STAC Collections are catalogs which describe a group of related items and thus they also contain dedicated metadata for those items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries\n",
    "\n",
    "To start, we will first import several libraries that will be useful for the rest of this exercise:\n",
    "\n",
    "- `pystac_client`: package for working with STAC Catalogs and APIs that conform to the STAC and STAC API specs in a seamless way\n",
    "- `planetary_computer`: package for working with Microsoft Planetary Computer API\n",
    "- `pandas`/`geopandas`: package that provides fast, flexible, and expressive (geo)data structures designed to make working with \"relational\" or \"labeled\" data both easy and intuitive\n",
    "- `shapely`: package for handling geospatial vector data\n",
    "- `folium`: package for visualizing spatial data via an interactive leaflet map\n",
    "- `numpy`: the fundamental package for scientific computing in Python\n",
    "- ... and some other tools..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# library for handling STAC data\n",
    "import pystac_client\n",
    "\n",
    "# library for accessing Microsoft Planetary Computer's STAC catalog\n",
    "import planetary_computer\n",
    "\n",
    "# dataframes and their geospatial data counterpart\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# library for vector data\n",
    "import shapely\n",
    "\n",
    "# visualization\n",
    "import folium #maps\n",
    "\n",
    "# NumPy arrays\n",
    "import numpy as np\n",
    "\n",
    "# miscellaneous\n",
    "from IPython.display import display\n",
    "import json\n",
    "from functools import partial\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3. How to handle a GeoJSON layer\n",
    "### 3.1. GeoJSON structure\n",
    "\n",
    "Here is an example of a simple GeoJSON Feature describing a rectangle Polygon: the `geometry` property and its `coordinates` sub-property are the most important, they contain the coordinates of the vertices of the polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"type\": \"Feature\",\n",
    "    \"geometry\": {\n",
    "        'type': 'Polygon',\n",
    "        'coordinates': \n",
    "            [\n",
    "                [[4.825087, 43.949066],\n",
    "                [4.919379, 43.949066],\n",
    "                [4.919379, 43.885034],\n",
    "                [4.825087, 43.885034],\n",
    "                [4.825087, 43.949066]]\n",
    "            ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For a slightly more elaborate approach, we will use the GeoJSON file **sample.geojson** that is a collection of features (polygons). In this case, there are 12 rectangles corresponding to different land cover classifications around the city of Montpellier (South of France). First, let's take a look at the geoJSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"sample.geojson\") as file:\n",
    "    features = json.load(file)\n",
    "\n",
    "print(f\"the geoJSON type is: {features['type']}\\n\")\n",
    "print(\"Example of geoJSON strcuture for the first feature:\\n\")\n",
    "print(json.dumps(features[\"features\"][0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise**: propose a loop to obtain the list of land cover types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to fill\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Displaying GeoJSON features on a map\n",
    "\n",
    "Here, we use Folium package to display the geometries of GeoJSON features through an interactive map.\n",
    "\n",
    "The first block of code is dedicated to some formattig settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configuring some formatting settings for the map visuals\n",
    "higlight_fn = lambda x: {'fillOpacity':0.5}\n",
    "FGJSON = partial(folium.GeoJson, highlight_function=higlight_fn, zoom_on_click=True)\n",
    "\n",
    "colors = cycle(['green', 'grey', 'orange', 'red', 'yellow', 'purple', 'pink','brown'])\n",
    "style_fn = lambda x: {'color':next(colors), 'fillOpacity':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the main part for displaying the GeoJSON features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"sample.geojson\") as file:\n",
    "    features = json.load(file)\n",
    "\n",
    "# We can use folium to easily visualize the polygons on a map\n",
    "maps = folium.Map(location=[43.6085, 4.0053], zoom_start=11, control_scale=True)\n",
    "polygon_group = folium.FeatureGroup(name='landcover polygons').add_to(maps)\n",
    "\n",
    "# these groups will only be used later but it needs to be created before rendering the map\n",
    "polygon_extent_group = folium.FeatureGroup(name='polygons extent', control=False).add_to(maps)\n",
    "sat_extent_group = folium.FeatureGroup(name='satellite extents', control=False).add_to(maps)\n",
    "\n",
    "maps.keep_in_front(polygon_group)\n",
    "maps.add_child(polygon_group)\n",
    "\n",
    "for feature in features['features']:\n",
    "   a = FGJSON(feature['geometry'], name=feature['properties']['landcover'])\n",
    "   polygon_group.add_child(a)\n",
    "\n",
    "folium.LayerControl().add_to(maps)\n",
    "\n",
    "maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Determining the bounding box of the GeoJSON layer\n",
    "\n",
    "Since we're dealing with multiple polygons, having an additional polygon which covers the full extent will prove useful. Here we will use `shapely` to get the bounds of a MultiPolygon object. However simply looping on each polygon and keeping track of minimums and maximums of latitude and longitude is a completely valid alternative, if a little more involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import shape, MultiPolygon, box\n",
    "\n",
    "# create a shapely MultiPolygon from each GeoJSON polygon\n",
    "union = MultiPolygon(shape(feature['geometry']) for feature in features['features'])\n",
    "# create a new Polygon from the bounds of the union\n",
    "extent = box(*union.bounds)\n",
    "\n",
    "# export as a GeoJSON object\n",
    "extent_geo_json = json.loads(shapely.to_geojson(extent))\n",
    "\n",
    "fgjson = folium.GeoJson(extent_geo_json, highlight_function = lambda x: {'fillOpacity':0}, style_function = style_fn )\n",
    "polygon_extent_group.add_child(fgjson)\n",
    "polygon_extent_group.control = True\n",
    "maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Exploring a STAC catalog\n",
    "\n",
    "We now want to list the Sentinel-2 images available on the previously calculated bounding box. Here, we will explore the *Microsoft Planetary Computer* catalog.\n",
    "\n",
    "### 4.1. STAC architecture\n",
    "\n",
    "#### 4.1.1. STAC catalog\n",
    "\n",
    "**STAC Catalog** can simply be seen as a directory of other STAC objects (Catalogs, Collection and Items). There are very little restrictions placed on Catalogs, the way they're organized tends to depend on the specific implementation.\n",
    "\n",
    "<figure align=\"center\">\n",
    "  <img src=\"resources/stac_catalog.jpg\" width=\"60%\" alt=\"STAC Item diagram\">\n",
    "  <figcaption>STAC Collection Layout and Specification </br> Figure by <a href=\"https://stacspec.org/\">https://stacspec.org/</a> (license <a href=\"https://creativecommons.org/licenses/by/4.0\">CC BY 4.0</a>)\n",
    "  </figcaption>\n",
    "</figure>\n",
    "\n",
    "#### 4.1.2. STAC Collection\n",
    "\n",
    "**STAC Collections** are built upon STAC Catalogs. Collections are meant to group homogeneous data, so they include additional fields to describe the data, such as spatial and temporal extent, license and other metadata.\n",
    "\n",
    "<figure align=\"center\">\n",
    "  <img src=\"https://d33wubrfki0l68.cloudfront.net/defe8206fe2240db920befa01f262e37d9036589/4f401/public/images-original/intro-images/stac-collection.png\" width=\"60%\" alt=\"STAC Item diagram\">\n",
    "  <figcaption>STAC Collection Specification </br> Figure by <a href=\"https://stacspec.org/\">https://stacspec.org/</a> (license <a href=\"https://creativecommons.org/licenses/by/4.0\">CC BY 4.0</a>)\n",
    "  </figcaption>\n",
    "</figure>\n",
    "\n",
    "#### 4.1.3. STAC Item\n",
    "\n",
    "**STAC Item** is built upon the [GeoJSON specification](https://geojson.org/). GeoJSON is a format for encoding different geometric data structures such as points, lines and polygons. It is widely used by standard geospatial libraries such as `Shapely`.\n",
    "\n",
    "<figure align=\"center\">\n",
    "  <img src=\"https://d33wubrfki0l68.cloudfront.net/beb4a5fa5d6685adc9b8baff73647bae404c6eb6/9e0e1/public/images-original/intro-images/stac-item.jpeg\" width=\"60%\" alt=\"STAC Item diagram\">\n",
    "  <figcaption>STAC Item Specification </br> Figure by <a href=\"https://stacspec.org/\">https://stacspec.org/</a> (license <a href=\"https://creativecommons.org/licenses/by/4.0\">CC BY 4.0</a>)\n",
    "  </figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Opening Planetary Computer's STAC Catalog \n",
    "\n",
    "#### 4.2.1. Microsoft API connection\n",
    "\n",
    "Let's start by opening a client object to the Planetary Computer STAC catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style='color:red'> **IMPORTANT:** The URLs that we obtain from the STAC Catalog are not valid indefinitely. They expire after about 30 minutes. If you see an error in the notebook, it is likely because the URL that you obtained has now expired.</span> If that happens you should be able to just run the notebook again from the top to get a new URL. You can get longer-lasting URLs by signing up for Planetary Computer (which is free at the time of writing this notebook). More info [here](https://planetarycomputer.microsoft.com/docs/concepts/sas/). \n",
    "\n",
    "Most of the objects we will be using in this notebook include rich text formatting and some HTML. That means we can easily have a look at objects by using the `display` function of `IPython.display` or simply using the default output behavior of the last line of the cell in notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#These two next lines are equivalent\n",
    "display(catalog)\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's have a look at the contents of the `catalog` object. This particular Catalog object we have created is the parent group of all the STAC objects that Planetary Computer provides.\n",
    "\n",
    "As a reference here is a list of the fields defined in the [STAC Catalog specification](https://github.com/radiantearth/stac-spec/blob/master/catalog-spec/catalog-spec.md).\n",
    "| Element         | Type          | Description                                                  |\n",
    "| --------------- | ------------- | ------------------------------------------------------------ |\n",
    "| type            | string        | **REQUIRED.** Set to `Catalog` if this Catalog only implements the Catalog spec. |\n",
    "| stac_version    | string        | **REQUIRED.** The STAC version the Catalog implements. |\n",
    "| stac_extensions | \\[string]     | A list of extension identifiers the Catalog implements.                 |\n",
    "| id              | string        | **REQUIRED.** Identifier for the Catalog.                    |\n",
    "| title           | string        | A short descriptive one-line title for the Catalog.          |\n",
    "| description     | string        | **REQUIRED.** Detailed multi-line description to fully explain the Catalog. [CommonMark 0.29](http://commonmark.org/) syntax MAY be used for rich text representation. |\n",
    "| links           | [[Link Object](#link-object)] | **REQUIRED.** A list of references to other documents.       |\n",
    "\n",
    "We can see that the `catalog` object does contain most of the required fields for a Catalog object. However it does not include the `stac_version` field, so it is not technically a completely valid Catalog object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. List of collections\n",
    "\n",
    "Now let's look at the Collection objects that are in `catalog`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collections = [(collection.id, collection.title) for collection in catalog.get_collections()]\n",
    "pd.set_option('display.max_rows', 150)\n",
    "# see if we can filter on access authorizations\n",
    "pd.DataFrame(collections, columns=['Collection ID', 'Collection Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.2.3. Exploring Sentinel-2 collection\n",
    "\n",
    "In the table above we can clearly see how each collection (i.e. each row) of Planetary Computer's catalog corresponds to a dataset with common properties. Let's now look at a collection in particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We use the collection id from the table above to obtain the collection object\n",
    "catalog_s2 = catalog.get_collection('sentinel-2-l2a')\n",
    "catalog_s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "By reading the `description` field, we can see that this collection contains all of the data from Sentinel-2 processed in Level-2A (bottom-of-atmosphere reflectance), ranging from 2016 to the present. It is obvious that looking through all this data in the same way that we did for the collections themselves would not be practical.\n",
    "\n",
    "The simplest way to search through a catalog is to use the [`search`](https://pystac-client.readthedocs.io/en/stable/api.html#pystac_client.Client.search) method on a catalog object.\n",
    "The important arguments for the search methods are the following:\n",
    "  - `collections`: restricts the search to the collections which `id` were provided\n",
    "  - restricting spatial extent using either:\n",
    "    - `bbox` : simple bounding box given as [min(longitude), min(latitude), max(longitude), max(latitude)]\n",
    "    - `intersects` : GeoJSON object, or an object implementing a `__geo_interface__` property (supported by libraries such as Shapely, ARcPy, PySAL, geojson)\n",
    "  - `datetime` : using a `datetime.datetime` object or a string. For a time range you can use `'yyyy-mm-dd/yyyy-mm-dd'` (beginning/end), or even  `'2017'` as a shortcut for `'2017-01-01/2017-12-31'`, and `2017-06` for the whole month of June 2017\n",
    "  - `query` : a list of JSON of query parameters. This allows to search for specific properties of items (such as cloud cover), and will be used in a later notebook\n",
    "\n",
    "**Note:** Finding GPS coordinates can be as simple as going to [google.com/maps](http://google.com/maps) and right clicking a point on the map. However, be careful that although standards dictate that coordinates should be given with latitude first and longitude second, some tools and libraries use longitude first and latitude second, often as a similarity to $(x,y)$ coordinates on a plane.\n",
    "\n",
    "For now, let's reuse the extent GeoJSON Polygon we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here longitude comes first\n",
    "area_of_interest = extent_geo_json\n",
    "area_of_interest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bbox` parameter expects a Python list formatted as follows:\n",
    "\n",
    "    [xmin, ymin, xmax, ymax]\n",
    "\n",
    "So we have to modify `area_of_interest` in order to keep the right coordinates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here is the equivalent bbox object to the polygon above\n",
    "# using a numpy array for convenient axis operations\n",
    "coords = np.array([area_of_interest['coordinates']][0][0])\n",
    "bbox = [*coords.min(0), *coords.max(0)]\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `datetime` parameter expects a start time and an end time formatted as follows:\n",
    "\n",
    "    \"start_date<yyyy-mm-dd>/end_date<yyyy-mm-dd>\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = \"2020-12-01/2020-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can search the Sentinel-2 images (or *STAC Items*) that match our criteria. Here we present the two ways to pass the spatial query (`bbox` and `intersects`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# the id for a collection can be found in the table we created earlier\n",
    "collections = ['sentinel-2-l2a']\n",
    "\n",
    "# As expected the GeoJSON object and\n",
    "# bounding box methods give the same results\n",
    "search = catalog.search(\n",
    "    collections=collections,\n",
    "    datetime=time_range,\n",
    "    bbox=bbox\n",
    ")\n",
    "items = search.get_all_items()\n",
    "print(f\"{len(items)} items found with the `bbox` parameter\")\n",
    "\n",
    "search = catalog.search(\n",
    "    collections=collections,\n",
    "    datetime=time_range,\n",
    "    intersects=area_of_interest\n",
    ")\n",
    "items = search.get_all_items()\n",
    "print(f\"{len(items)} items found with the `intersects` parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of a search is an `ItemCollection`, which is similar to the objects we've seen previously. Thus we can look through it just the same with `display` or Jupyter's cell magic. We can then check that the results are from the right dataset (Sentinel-2 L2A), the right date ranges, and the geometry we specified falls within the specified `bbox` of each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The results of the search are STAC Item objects. Here each Item corresponds to an acquisition of Sentinel-2. Each Item contains Assets. If we look through the assets of one of the search result, we see that each band corresponds to an asset, but we also have additional assets like the Scene Classification Layer (SCL) which attempts to classify pixels within 12 classes (including No Data, defective pixel, cloud, snow or ice, vegetation, etc.). As mentioned previously, **there is no data in an Asset object**, only a link to the data (the `href` property).\n",
    "\n",
    "An other thing to note is the STAC Extensions section. STAC is meant to be very general and does not make many assumptions to the nature of the data it describes. This is why STAC Extensions can be created to help extend the basic scheme. The items we obtained all implement three extensions:\n",
    "  - `eo` : Electro-Optical Extension Specification which helps describe data that represents a snapshot of the Earth for a single date and time\n",
    "  - `sat` : Satellite Extension Specification which helps describe metadata related to a satellite\n",
    "  - `projection` : Projection Extension Specification which helps describe data related to the projection of GIS data (CRS, geometry, bbox, shape, etc.)\n",
    "\n",
    "STAC extensions can be freely created, but most are released and described at https://stac-extensions.github.io/.\n",
    "\n",
    "It may be more convenient to import the search result items into a table with a library like `geopandas`.\n",
    "\n",
    "> **Exercise**: search how many landsat images (collection: 'landsat-c2-l2') intersect our area of interest between 2020-12-01 and 2020-12-31.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to fill\n",
    "# ...\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Finding the less cloudy image\n",
    "\n",
    "#### 4.3.1. Management of coordinate systems\n",
    "\n",
    "The `crs` argument refers to Coordinate Reference System. A CRS is a coordinate-based system used to locate geographical entities. The [EPSG registry](https://epsg.org/home.html) is a public registry of such coordinate systems. The GPS coordinates we have handled so far are defined in a coordinate system which EPSG code is EPSG:4326. Since GPS coordinates are so widely known and available, they have become a *de facto* standard for handling geospatial data. In most situations, if a coordinate system is not specified it is safe to assume that coordinates are given in EPSG:4326.\n",
    "\n",
    "***Note:** The EPSG database specifies the order of the axis. For instance (latitude, longitude) is the order of axis for EPSG:4326, with units going up in the north and east directions. However, as mentioned previously, some libraries and programs ignore this part of the standard. They instead choose (longitude, latitude) as their default.*\n",
    "\n",
    "For Planetary Computer itself, that standard becomes crucial. Even within a collection the CRS might not be the same. For example Sentinel-2 uses the Universal Transverse Mercator (UTM) system. This system divides the Earth into 60 zones of 6° of longitude in width. Furthermore, for a same UTM zone the CRS is also different in the northern and southern hemispheres. In total, depending on the location, Sentinel-2 data uses one of 120 different CRS! In order to permit searching with a bounding box or intersects, the `bbox` field of Items uses GPS coordinates, even if the underlying data uses a different coordinate system.\n",
    "\n",
    "#### 4.3.2. Converting Items to GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = gpd.GeoDataFrame.from_features(items.to_dict(), crs=\"epsg:4326\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `geometry` property of the assets to visualize the extent of each satellite image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extents = json.loads(df['geometry'].to_json())\n",
    "for feature in extents['features']:\n",
    "    folium.GeoJson(feature['geometry'],\n",
    "                   style_function=style_fn\n",
    "                   ).add_to(sat_extent_group)\n",
    "sat_extent_group.control = True\n",
    "maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3. Question of the orbit\n",
    "\n",
    "It appears that we have two different shapes of images. In fact, it appears that for some of the images the edge goes right through one of our polygons. That's an important point to note: the search matches any intersection between the area of interest and the extent, not a complete inclusion.\n",
    "\n",
    "This is where the `sat` STAC extension can help us. Indeed if we look at the `sat:relative_orbit` we can see that there are two orbits which acquisitions overlap with our area of interest, which means two different shapes for the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Orbit numbers are {df['sat:relative_orbit'].unique()}\\n---\")\n",
    "print(\"Relative orbit number 108\")\n",
    "display(df[df['sat:relative_orbit']==108]['geometry'].head(1).item())\n",
    "print(\"Relative orbit number 8\")\n",
    "df[df['sat:relative_orbit']==8]['geometry'].head(1).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the images from orbit 108 only a have a very small intersection with the area of interest. So let's restrict ourselves to orbit 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "items = [item for item in items if item.properties[\"sat:relative_orbit\"]==8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4. Filtering by cloud cover\n",
    "\n",
    "As we've seen before, the `'sentinel-2-l2a'` collection implements the `eo` extension (as indicated in the STAC extension section of the Item). This means we can use the `eo:cloud_cover` field to select the item (i.e. acquisition date) with the lowest cloudiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_item = min(items, key=lambda item: item.properties[\"eo:cloud_cover\"])\n",
    "print(f\"The lowest cloudiness has a value of {selected_item.properties['eo:cloud_cover']} for date {selected_item.datetime}\")\n",
    "selected_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.5. Item's Assets\n",
    "\n",
    "Finally let's have a look at the assets for that item we selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values = [asset.title for asset in selected_item.assets.values()]\n",
    "descriptions = pd.DataFrame(values, columns=['Description'], index=pd.Series(selected_item.assets.keys(), name='asset_key'))\n",
    "descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rendered_preview` asset can prove quite useful: it is a way to quickly visualize an image without having to select each band to create a color composite. The `Image` class from `IPython.display` allows us to use a URL to display an image, and this is precisely what the `href` property of the asset contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_item.assets[\"rendered_preview\"].to_dict()\n",
    "from IPython.display import Image\n",
    "Image(url=selected_item.assets[\"rendered_preview\"].href, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise**: Display the least cloudy landsat image (preview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to fill\n",
    "# ...\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
