{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Opening a Sentinel-2 image with rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Author(s):** Quentin Yeche, Kenji Ose, Dino Ienco - [UMR TETIS](https://umr-tetis.fr) / [INRAE](https://www.inrae.fr/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "In this notebook we will cover basic usage of Python's `rasterio` library in order to download and manipulate satellite imagery. In a first time, we will handle single-band and single-date imagery. Then, we will handle multi-band images and discover color composites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries\n",
    "\n",
    "As usual, we import all the required Python libraries. Th new one is `rasterio`, a package for accessing the many different kind of raster data files used in the GIS field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STAC access\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "\n",
    "# dataframes and their geospatial data counterpart\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# library for handling GIS rasters\n",
    "import rasterio as rio\n",
    "import rasterio.mask\n",
    "\n",
    "# library for vector data\n",
    "import shapely\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# library for tranforming coordinates\n",
    "from pyproj import Transformer\n",
    "\n",
    "#visualization\n",
    "import folium #maps\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# NumPy arrays\n",
    "import numpy as np\n",
    "\n",
    "# miscellanous\n",
    "from IPython.display import display\n",
    "import json\n",
    "import rich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Obtaining an Asset and looking at its properties\n",
    "\n",
    "### 3.1. Opening landcover data and Sentinel-2 image\n",
    "\n",
    "Let's reuse the example from the [STAC notebook](./Joensuu_01-STAC.ipynb). We have a GeoJSON of some polygons that make up our area of interest. We have also identified the ID of the STAC `Item` we want to use (it of course encompasses our area of interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# polygons defining our area of interest\n",
    "with open(\"./sample.geojson\") as file:\n",
    "    geojson_feature = json.load(file)\n",
    "\n",
    "# retrieving the relevant STAC Item\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    "    )\n",
    "\n",
    "item = catalog.get_collection('sentinel-2-l2a').get_item(\"S2A_MSIL2A_20201213T104441_R008_T31TEJ_20201214T083443\")\n",
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2. Sentinel-2 Item's assets\n",
    "\n",
    "#### 3.2.1. Listing assets of Sentinel-2 image\n",
    "\n",
    "First, let's have a look at the list of assets available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assets = [asset.title for asset in item.assets.values()]\n",
    "descriptions = pd.DataFrame(assets, columns=['Description'], index=pd.Series(item.assets.keys(), name='asset_key'))\n",
    "descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this table, we can easily find the IDs (*asset_key*) of the assets we are looking for. \n",
    "\n",
    "#### 3.2.2. Basic description of a Sentinel-2 spectral band\n",
    "\n",
    "Let's choose the blue band ('B02'). Rather than directly loading the data, we will only access the `profile` property for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(item.assets['B02'].href) as ds:\n",
    "    profile = ds.profile\n",
    "rich.print(profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `profile` property has two fields we will use shortly. \n",
    "\n",
    "The first is `crs` or Coordinate Reference System, which specifies the geospatial coordinate system that the data uses. In this case the CRS is EPSG:32631. As we have seen in the [previous notebook](./Joensuu_01-STAC.ipynb), the polygons defining our area of interest are GPS coordinates, i.e. they use the EPSG:4326 CRS. Thus we have a different coordinate systems for our satellite image and our polygons. This means we will have to convert one into the other before we can work with both. It is usually recommended to preserve the CRS of the imagery (in order to avoid pixel value tranformation with resampling methods). In our case, we will convert the coordinates of our polygons into EPSG:32631.\n",
    "\n",
    "The second field is `transform`. It describes how to relate geospatial coordinates and pixels. Here's a description of the six values given:\n",
    " ```\n",
    "[0] cos(θ) * x_resolution\n",
    "[1] -sin(θ) * x_resolution\n",
    "[2] x-coordinate of upper-left raster corner\n",
    "[3] sin(θ) * y_resolution\n",
    "[4] cos(θ) * y_resolution\n",
    "[5] y-coordinate of upper-left raster corner\n",
    " ```\n",
    "\n",
    "Here (and in most situations) the affine transformation includes no rotation. Since $θ=0$ the previous list can be re-written as:\n",
    "```\n",
    "[0] x_resolution\n",
    "[1] 0\n",
    "[2] x-coordinate of upper-left raster corner\n",
    "[3] 0\n",
    "[4] y_resolution\n",
    "[5] y-coordinate of upper-left raster corner\n",
    "```\n",
    "Thus when reading the `transform` field we can deduce the following:\n",
    "1. Each pixel has a width corresponding to 10 units in the CRS. For our CRS the units are meters, so a pixel width of 10 meters.\n",
    "2. The upper-left corner of the satellite image corresponds to a point with geospatial coordinates (499980.0,4900020.0)\n",
    "3. Each pixel has a height corresponding to -10 meters.\n",
    "\n",
    "Note: A negative pixel height may seem confusing. But it simply captures the following dichotomy:\n",
    "1. In an image stored as data, it is standard for the origin to be placed at the upper-left corner. Pixel coordinates increase as you go right, and down.\n",
    "2. In most CRS (and indeed it's the case for EPSG:32631), coordinate values increase as you go east, and **north**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Getting the relevant part of satellite image\n",
    "\n",
    "The reason we retrieve the CRS and transformation matrix before accessing the data itself is a matter of efficiency. We are only interested in a certain area of interest (defined by the GeoJSON file). `rasterio` and the file format of the data (Cloud Optimized GeoTiff or COG) allow us to only download the relevant part of an image, rather than downloading the full image and then cropping it.\n",
    "\n",
    "As a test you can try downloading the full band by uncommenting and running the following cell. A typical size of a Sentinel-2 is in the hundreds of megabytes. In most projects it is not uncommon to use multiple bands and possibly multiple dates. So reducing the amount of data we need to download is alway a good practice, especially to help with download times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with rio.open(item.assets['B02'].href) as ds:\n",
    "    data = ds.read()\n",
    "    print(data.nbytes)\n",
    "    print(f\"Total size of the data is {data.nbytes//(2**20)} MB\")\n",
    "\"\"\"\n",
    "None #only there to prevent the string to be output by Jupyter's cell magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see two approaches to obtaining the relevant data: using a window for the extent, and using masks.\n",
    "\n",
    "### 4.1. Using a window with `rasterio`\n",
    "\n",
    "If we use a window, we will obtain the reflectance data for the whole extent. This has the advantage of giving us context around each of our polygons. Among others, it can be useful to quickly check whether the area is cloudy (although we will see better methods for that later).\n",
    "\n",
    "#### 4.1.1. Creating a bounding box\n",
    "First let's create a bounding box from all the polygons, and convert the bounds to EPSG:32631 using `rasterio.warp.transform_bounds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multipolygon = shapely.geometry.MultiPolygon([shape(feature['geometry']) for feature in geojson_feature['features']])\n",
    "aoi_bounds = multipolygon.bounds\n",
    "print(f\"bounds in EPSG:4326 {aoi_bounds}\")\n",
    "converted_aoi_bounds = rio.warp.transform_bounds(\"epsg:4326\", profile['crs'], *aoi_bounds)\n",
    "print(f\"bounds after conversion to EPSG:32631 {converted_aoi_bounds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these bounds we can create a `Window` object. We need to specify the affine transform of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aoi_window = rio.windows.from_bounds(*converted_aoi_bounds, transform = profile['transform'])\n",
    "aoi_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the output of the last cell that the Window object describes the offsets and length of pixel coordinates on the satellite image, so the affine transformation has been applied. The values are floating point numbers instead of integers, but they will automatically be rounded later on.\n",
    "\n",
    "#### 4.1.2. Reading the data\n",
    "\n",
    "At this point we are ready to read the data for our band, downloading only the window which encompasses our area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(item.assets['B02'].href) as ds:\n",
    "    band = ds.read(window=aoi_window)\n",
    "print(f\"Type: {type(band)} \\nShape: {band.shape}\\nTotal size: {band.nbytes//2**20} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the `read` method is a NumPy array. At this point the data has been downloaded, but only the necessary parts for the window we specified. This is reflected in both the shape and size of the array, as well as the time required for execution.\n",
    "\n",
    "There are two things worthy of note concerning the shape of the NumPy array. The first is that it has three dimensions: (channels, height, width). This even applies in our case where there is a single band, so a single channel. This is mostly a matter of consistency, as most geospatial library do not generally differentiate between single-band and multi-band data, hence they always expect a 3-dimensional array. The second important point is that the order of dimensions does not respect the typical (height, width, channels) convention used for images.\n",
    "\n",
    "A result of those points is that when we want to manipulate the data with general-purpose tools we may have to re-order the dimensions with `transpose` and/or remove the extra channel dimension of size 1 using the `squeeze` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#here we use the squeeze method to remove axes of length one\n",
    "print(band.squeeze().shape)\n",
    "plt.imshow(band.squeeze(), cmap='RdGy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2. Using masks with `rasterio`\n",
    "\n",
    "By using masks, we can choose to only keep the reflectance values inside our polygons that define our area of interest. This means that adjusting the contrast can be more relevant as we are not calculating statistics on the whole extent. However we would need to account for the fact that any pixel outside our area of interest does still have a value of 0.\n",
    "\n",
    "#### 4.2.1. Converting the MultiPolygon into another CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = Transformer.from_crs('epsg:4326', 'epsg:32631', always_xy=True).transform\n",
    "multipolygon_warped = shapely.ops.transform(transform, multipolygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(item.assets['B02'].href) as ds:\n",
    "    out_image, out_transform = rio.mask.mask(ds, [multipolygon_warped], crop=True)\n",
    "\n",
    "print(out_image.squeeze().shape)\n",
    "plt.imshow(out_image.squeeze(), cmap='RdGy')#'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Adjusting the contrast for visuals\n",
    "\n",
    "### 5.1. Distribution of pixel values of the image\n",
    "\n",
    "With `matplotlib` we can visualize the image. However it looks very dark. This is quite typical for satellite imagery. A minority of pixels will record very high reflectance values, and default normalization will bring down the contrast on the rest of the pixels. This is easily illustrated with a quick histogram on the pixel values of the image clipped with the `rasterio` window:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(band.reshape(-1), bins=30)\n",
    "plt.show()\n",
    "print(f\"Max value: {band.max()}\")\n",
    "print(f'{np.count_nonzero(band > 2500)/(band.size):.1%} of values higher than 2500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Image contrast\n",
    "\n",
    "We can see that the majority of values fall between 0 and 2000. For producing visuals it is thus helpful to set a cutoff point and clip the values above it. Here we arbitrarily choose 2500 but some standards practices include using  percentiles (usually [2-98] or [5-95]) or defining intervals based on the standard deviation of the data. Here's one way to clip the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting min and max with Percentiles [2-98] method\n",
    "m1_min = (np.percentile(band, 2))\n",
    "m1_max = (np.percentile(band, 98))\n",
    "print(f\"Percentiles method: min={m1_min} ; max={m1_max}\")\n",
    "\n",
    "# Getting min and max with Standard deviation method\n",
    "m2_mean = band.mean()\n",
    "m2_stdv = band.std()\n",
    "print(f\"Percentiles method: min={int(band.mean()-band.std())} ; max={int(band.mean()+band.std())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we plot the Sentinel-2 band, before and after values stretching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "band_visual = band.squeeze().copy()\n",
    "band_visual[band_visual>2500] = 2500\n",
    "\n",
    "f = plt.figure()\n",
    "f.add_subplot(1,2, 1)\n",
    "plt.imshow(band.squeeze(), cmap='gray')\n",
    "plt.title('before')\n",
    "f.add_subplot(1,2, 2)\n",
    "plt.imshow(band_visual, cmap='gray')\n",
    "plt.title('after')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However `imshow` already provides us with tools to specify some cutoff point: `vmax`. Any value higher than this value will be clipped down to that cutoff.\n",
    "\n",
    "**Note:** There also exists `vmin` to specify a lower bound cutoff but since reflectance values are often grouped near zero this cutoff is typically less useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(band.squeeze(), vmax=2500, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise**: Plot the Sentinel-2 band with percentiles and standard deviation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to fill\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Visualization on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize the band over a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# once again, standards for bounding box coordinates can differ\n",
    "b = [[aoi_bounds[1], aoi_bounds[0]], [aoi_bounds[3], aoi_bounds[2]]]\n",
    "maps = folium.Map(tiles=None, location=[43.6085, 4.0053], zoom_start=11, control_scale=True)\n",
    "folium.TileLayer(\"http://mt0.google.com/vt/lyrs=s&hl=en&x={x}&y={y}&z={z}\", attr='Google', name='Google Satellite').add_to(maps)\n",
    "folium.TileLayer(name='OpenStreetMap').add_to(maps)\n",
    "folium.raster_layers.ImageOverlay(out_image.squeeze(), bounds=b,overlay=True, cross_origin=False, name=\"B02_mask\").add_to(maps)\n",
    "folium.raster_layers.ImageOverlay(band_visual, bounds=b,overlay=True, cross_origin=False, name=\"B02_window\").add_to(maps)\n",
    "folium.LayerControl().add_to(maps)\n",
    "\n",
    "maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Management of color composites\n",
    "\n",
    "We will now load several spectral bands and projet them through the RGB color space in order to produce colored images, or color composites. It is based on the principale of additive color:\n",
    "\n",
    "<figure align=\"center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Synthese%2B.svg/1024px-Synthese%2B.svg.png\" width=\"30%\" alt=\"additive color\">\n",
    "  <figcaption>STAC Collection Specification </br> Figure by <a href=\"https://commons.wikimedia.org/w/index.php?curid=818982\">Wikipedia</a> (license <a href=\"https://creativecommons.org/licenses/by/3.0\">CC BY-SA 3.0</a>)\n",
    "  </figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n",
    "In the world of remote sensing, there are two well-known color composites:\n",
    "\n",
    "- the **natural colors composite**, or true colors, consists in assigning respectively to the red, green and blue filters the red, green and blue spectral bands. On display, the color reproduction is very close to what a human could perceive from space. Vegetation appears in shades of green, water in blue, urban areas in light gray.\n",
    "- the **false-color composite** images display spectral bands which are different from primary colors. In fact, the color of the objects does not correspond to their “real” color as our eye would perceive it. The false-color is used to highlight certain objects in the image, taking advantage of their spectral signature. Therefore, the composition in infrared false colors is commonly used to study vegetation. It is generally accepted that the infrared, red and green spectral bands are allocated, respectively, to the red, green and blue filters. Vegetation is seen in red since its reflectance is at its maximum in the infrared. The shades vary according to the chlorophyll activity of the species in the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Loading 10m Sentinel-2 spectral bands\n",
    "\n",
    "Here, we will produce color composites based on Sentinel-2 10m spectral bands: 'B02', 'B03','B04' and 'B08'. In the first time, we have to load each asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rio.open(item.assets['B02'].href) as ds:\n",
    "    band_blue = ds.read(window=aoi_window)\n",
    "with rio.open(item.assets['B03'].href) as ds:\n",
    "    band_green = ds.read(window=aoi_window)\n",
    "with rio.open(item.assets['B04'].href) as ds:\n",
    "    band_red = ds.read(window=aoi_window)\n",
    "with rio.open(item.assets['B08'].href) as ds:\n",
    "    band_nir = ds.read(window=aoi_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Normalize band values\n",
    "\n",
    "In order to display RGB image with `matplotlib`, we need to normalize each band between \\[0, 1\\]. To do this, we propose to define a function called `normalize`. It takes two arguments:\n",
    "- array: numpy ndarray for each band\n",
    "- vmax: max pixel value in order to improve the contrast of the output band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to normalize the grid values\n",
    "def normalize(array, vmax=False):\n",
    "    \"\"\"Normalizes numpy arrays into scale 0.0 - 1.0\"\"\"\n",
    "    if vmax:\n",
    "        array[array>vmax] = vmax\n",
    "    array_min, array_max = array.min(), array.max()\n",
    "    return ((array - array_min)/(array_max - array_min))\n",
    "\n",
    "band_blue_n = normalize(band_blue, 2500)\n",
    "band_green_n = normalize(band_green, 2500)\n",
    "band_red_n = normalize(band_red, 2500)\n",
    "band_nir_n = normalize(band_nir, 2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6.3. Bands stacking and display\n",
    "\n",
    "We stack all the bands to produce a natural color composite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgb = np.stack((band_red_n, band_green_n, band_blue_n))\n",
    "rgb_natcol = np.moveaxis(rgb.squeeze(), 0, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, we can plot the RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(rgb_natcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise**: Display a infrared false color composite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fill\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**:\n",
    "> - Why vegetation appears in red?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".........................................\n",
    ".........................................\n",
    "........................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question**:\n",
    "    - Could you propose a infrared false color composite where vegetation appears in green?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".........................................\n",
    ".........................................\n",
    "........................................."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
